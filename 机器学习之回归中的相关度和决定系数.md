
@[TOC](目录)

 * * *
机器学习中关于回归模型有时候需要衡量自变量和因变量之间的相关度，接下来介绍两个衡量相关度的指标：
## 1. 相关度

### 1.1 相关度(Relevancy)
相关度是指两个事物间存在相互联系的百分比
相关度使用**皮尔逊相关系数**来进行衡量：
取值：[-1,1] 
该值>0 表示两个变量之间是正相关的，值为0表示两个变量之间无相关性，值<0表示两个变量之间是负相关的
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615103851344.png#pic_center)
皮尔逊相关系数的计算公式可以表示为： 
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615102525599.png#pic_center)
### 1.2 应用实例
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615102852559.png#pic_center)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615103047431.png#pic_center)
X_bar:X的平均值
Y_bar:Y的平均值
得到![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615103532226.png#pic_center)
正相关，r值越接近1或者-1相关度就越强
## 2. 决定系数(R^2)
决定系数反映因变量的全部变异能通过回归关系被自变量解释的比例 
该值越高说明模型越好
比如 R平方值为0.8，表示在所有因变量（也就是y）的变化中，其中80%可以由该回归模型解释，也就是该回归模型可以解释因变量80%的变异，也就是说，如果我们控制自变量不变，那么因变量的变化程度可以减少80%
简单线性回归：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615105146511.png#pic_center)
多元线性回归： 
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615105218359.png#pic_center)
SSR：由我们建立的模型能够解释
SST：因变量整体的变异也就是y的整体变化，其中一部分可以由我们的模型来解释（即SSR）
此外还有一部分SSE：对于y的整体变化除了模型解释的成分以外的误差项 也就是真实值和由模型估计值之间的差值 
y_hat(顶上有^)：直线上的值（估计值）
yi：小点的值（真实值）
所以

    SST=SSR+SSE
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615110447585.png#pic_center)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615105944197.png#pic_center)
但是R平方也会有局限性，R平方会随着样本量的增大而增加，R平方和样本量是有关系的，因此我们要对R平方进行修正：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190615110617401.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzMjA4ODUx,size_16,color_FFFFFF,t_70#pic_center)
N：样本量
p：有多少值要进行预测 
这样就可以抵消样本量对R平方的影响
